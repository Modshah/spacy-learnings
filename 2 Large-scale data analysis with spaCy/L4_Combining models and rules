Combining models and rules


Statistical predictions vs. rules
							Statistical models														Rule-based systems
Use cases		   :	Application needs to generalize based on examples						dictionary with finite number of examples
Real-world examples:	Product names, person names, subject/object relationships				countries of the world, cities, drug names, dog breeds
spaCy features	   :	entity recognizer, dependency parser, part-of-speech tagger				tokenizer, Matcher, PhraseMatcher



Adding statistical predictions
	matcher = Matcher(nlp.vocab)
	matcher.add("DOG", None, [{"LOWER": "golden"}, {"LOWER": "retriever"}])
	doc = nlp("I have a Golden Retriever")

	for match_id, start, end in matcher(doc):
		span = doc[start:end]
		print("Matched span:", span.text)
		# Get the span's root token and root head token
		print("Root token:", span.root.text)
		print("Root head token:", span.root.head.text)
		# Get the previous token and its POS tag
		print("Previous token:", doc[start - 1].text, doc[start - 1].pos_)
		


Efficient phrase matching (1)
PhraseMatcher like regular expressions or keyword search â€“ but with access to the tokens!
	Takes Doc object as patterns
	More efficient and faster than the Matcher
	Great for matching large word lists

Efficient phrase matching (2)
	from spacy.matcher import PhraseMatcher

	matcher = PhraseMatcher(nlp.vocab)

	pattern = nlp("Golden Retriever")
	matcher.add("DOG", None, pattern)
	doc = nlp("I have a Golden Retriever")

	# Iterate over the matches
	for match_id, start, end in matcher(doc):
		# Get the matched span
		span = doc[start:end]
		print("Matched span:", span.text)
	Matched span: Golden Retriever

